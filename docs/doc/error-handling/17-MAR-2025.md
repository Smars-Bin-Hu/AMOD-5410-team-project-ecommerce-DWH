# Troubleshooting: java.lang.NoClassDefFoundError: org/apache/hc/client5/http/io/HttpClientConnectionManager

## Error Description

When running the following Spark job to write Hive-based Parquet data to ClickHouse:

```python
from pyspark.sql import SparkSession
import clickhouse_connect

jar_files = [
    "/opt/spark/jars/clickhouse-jdbc-0.8.0-all.jar"
]

spark = SparkSession.builder \
    .appName("HiveToClickHouse") \
    .enableHiveSupport() \
    .config("spark.jars", ",".join(jar_files)) \
    .getOrCreate()

url = "jdbc:clickhouse://***:8443"
user = "default"
password = "****"
driver = "com.clickhouse.jdbc.ClickHouseDriver"

path_to_hdfs_parquet = "/user/hive/warehouse/dws/dws_orders_detailed_info_wide_ipd/data_date=2025-03-10/part-00000-24c51043-df4f-46af-87fc-b1034cdc2db1.c000.snappy.parquet"
df = spark.read.parquet(f"hdfs://ns-ha{path_to_hdfs_parquet}")

df.write \
    .format("jdbc") \
    .option("driver", driver) \
    .option("url", url) \
    .option("user", user) \
    .option("password", password) \
    .option("dbtable", "ads_data_mart_ecomerce.ads_orders_detailed_info_wide_ipd") \
    .mode("overwrite") \
    .save()

spark.stop()
```

the following warning and error appear in the logs:

```
WARN ClickHouseHttpConnectionFactory: Error when creating APACHE_HTTP_CLIENT, fall back to HTTP_URL_CONNECTION
java.lang.NoClassDefFoundError: org/apache/hc/client5/http/io/HttpClientConnectionManager
```

The key portion is:
```
Caused by: java.lang.ClassNotFoundException: org.apache.hc.client5.http.io.HttpClientConnectionManager
...
```

---

## Root Cause

Even though a file named `clickhouse-jdbc-0.8.0-all.jar` is used, the package does not actually contain all required Apache HttpClient 5 classes. ClickHouse JDBC versions 0.6.x and higher rely on Apache HttpClient 5 for advanced HTTP operations. If the required `org.apache.hc.client5` classes are not bundled in the JAR or are otherwise missing in the classpath, ClickHouse will try to initialize the Apache HTTP client but fail due to a missing class. It then falls back to the Java built-in `HttpURLConnection`.

In short, the `"all"` classifier of the JDBC JAR can be misleading in newer versions. Additional dependencies such as `httpclient5` or `clickhouse-client` may need to be included manually.

---

## Solutions

### 1. Use Maven Packages to Pull in All Dependencies

You can rely on Spark's built-in package resolution to automatically fetch dependencies from a Maven repository. For example:

```bash
spark-submit \
  --master yarn \
  --deploy-mode cluster \
  --org.apache.httpcomponents.client5:httpclient5:5.2 \
  your_script.py
```

This approach tells Spark to download `clickhouse-jdbc` and `httpclient5` from Maven. Make sure the versions are compatible according to ClickHouse's version compatibility matrix. After this, no additional manual JAR placement should be required.

### 2. Manually Download and Include the Additional JARs

If your Spark cluster cannot access Maven central or you prefer to manage JARs directly, you will need to download and provide all required libraries:

1. Download `httpclient5` (and possibly `httpcore5`) that matches your JDBC driver requirements:
   ```bash
   wget https://repo1.maven.org/maven2/org/apache/httpcomponents/client5/httpclient5/5.2/httpclient5-5.2.jar
   wget https://repo1.maven.org/maven2/org/apache/httpcomponents/core5/httpcore5/5.2/httpcore5-5.2.jar
   ```
2. Include them in your Spark job submission alongside the JDBC JAR:
   ```bash
   spark-submit \
     --master yarn \
     --deploy-mode cluster \
     --jars /path/to/clickhouse-jdbc-0.8.0-all.jar,/path/to/httpclient5-5.2.jar,/path/to/httpcore5-5.2.jar \
     your_script.py
   ```

With these additional JARs, Spark should be able to locate and load `org.apache.hc.client5.http.io.HttpClientConnectionManager` successfully.

---

## Summary

This warning and subsequent `NoClassDefFoundError` occur because the so-called `-all.jar` for ClickHouse JDBC does not contain Apache HttpClient 5 in the newer versions of ClickHouse JDBC. To fix the issue, add the missing HttpClient 5 dependencies. You can either do this automatically via Spark packages or manually by downloading the required JARs and specifying them in the `spark-submit` command. Once the relevant classes are present in the classpath, ClickHouse will properly initialize its Apache HTTP client without falling back to `HTTP_URL_CONNECTION`.
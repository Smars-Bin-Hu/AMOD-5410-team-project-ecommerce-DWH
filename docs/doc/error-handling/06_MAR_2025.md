# Error Handling Log: YARN Web UI Log Loading Failures

## Issue Description
- After a YARN application completes, clicking the **Logs** link in the YARN Web UI intermittently returns the following error:
  ```log
  Local Logs:
  java.lang.Exception: Unknown container. Container either has not started or has already completed or doesn't belong to this node at all.
  ```
- Logs are accessible via the CLI command `yarn logs -applicationId`, but the Web UI fails to display them.

---

## Root Causes
1. **Log Aggregation Disabled or Delayed**  
   YARN stores logs locally on NodeManager nodes by default. If log aggregation to HDFS is not enabled or delayed, and the container resources are released, the Web UI cannot access local logs.
2. **Misconfigured Log Server URL**  
   The `yarn.log.server.url` is not configured, causing the Web UI to redirect to NodeManager's local path instead of the aggregated HDFS logs.
3. **History Server Not Running**  
   The Hadoop MapReduce History Server is required to serve aggregated logs via the Web UI.

---

## Solutions

### 1. Configure YARN Log Aggregation
Add the following configurations to `yarn-site.xml`:
```xml
<!-- Enable log aggregation -->
<property>
  <name>yarn.log-aggregation-enable</name>
  <value>true</value>
</property>

<!-- Retention period for aggregated logs (7 days) -->
<property>
  <name>yarn.log-aggregation.retain-seconds</name>
  <value>604800</value>
</property>

<!-- Trigger aggregation immediately after job completion -->
<property>
  <name>yarn.log-aggregation.retain-check-interval-seconds</name>
  <value>-1</value>
</property>

<!-- URL for accessing aggregated logs -->
<property>
  <name>yarn.log.server.url</name>
  <value>http://hadoop-master:19888/jobhistory/logs</value>
</property>

<!-- Delay deletion of local logs (24 hours) -->
<property>
  <name>yarn.nodemanager.delete.debug-delay-sec</name>
  <value>86400</value>
</property>
```

### 2. Configure and Start History Server
Add these configurations to `mapred-site.xml`:
```xml
<property>
  <name>mapreduce.jobhistory.address</name>
  <value>hadoop-master:10020</value>
</property>
<property>
  <name>mapreduce.jobhistory.webapp.address</name>
  <value>hadoop-master:19888</value>
</property>
```

Start the History Server:
```bash
mr-jobhistory-daemon.sh start historyserver
```

### 3. Adjust Spark Submit Command
Add a wait time for log aggregation in the `spark-submit` command:
```bash
spark-submit --master yarn \
  --deploy-mode cluster \
  --conf spark.hadoop.yarn.log-aggregation.wait.ms=60000 \  # Wait for aggregation
  ...  # Other parameters
```

---

## Verification Steps

### 1. Check Aggregated Logs in HDFS
```bash
hdfs dfs -ls /tmp/logs/<YARN_USER>/logs/application_*

# Example output:
# -rw-r-----   3 yarn yarn     123456 2025-03-05 15:00 /tmp/logs/root/logs/application_1741204244706_0002/container_0012_01_000001/stdout
```

### 2. Retrieve Logs via CLI
```bash
yarn logs -applicationId application_1741204244706_0002 > app.log
```

### 3. Validate Web UI Access
1. Open the **ResourceManager Web UI**: `http://hadoop-worker1:8089`.
2. Click the application's **Tracking URL**, which should redirect to the History Server (e.g., `http://hadoop-master:19888`).
3. Click **Logs** on the History Server page to view aggregated logs.

---

## Troubleshooting

### 1. If Web UI Still Shows "Unknown Container"
- **Verify History Server Status**:
  ```bash
  jps | grep JobHistoryServer  # Ensure the process is running
  curl -I http://hadoop-master:19888  # Check HTTP response code
  ```
- **Confirm Port Mapping**:
  ```bash
  netstat -tuln | grep 19888  # Ensure the port is open on the host
  ```

### 2. If Logs Are Not Aggregated to HDFS
- **Check NodeManager Logs**:
  ```bash
  tail -f /var/log/hadoop-yarn/yarn-yarn-nodemanager-*.log
  # Look for "Aggregation" errors
  ```
- **Trigger Log Aggregation Manually**:
  ```bash
  yarn logs -applicationId <APP_ID> -log_files stdout
  ```

---

## Summary
- **Critical Configurations**:
  - Enable YARN log aggregation and set `yarn.log.server.url`.
  - Start the Hadoop History Server and ensure it is accessible.
- **Core Principle**:
  - The Web UI should access aggregated logs via the History Server (HDFS) instead of NodeManager local paths.
- **Tooling**:
  - Always use `yarn logs` to validate log availability first.

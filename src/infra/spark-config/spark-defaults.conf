# Spark on Yarn
spark.master                     yarn
spark.submit.deployMode          cluster

# driver and executor resources
spark.executor.instances         2
spark.executor.memory            2g
spark.driver.memory              1g
spark.executor.cores             1

# Hadoop & HDFS
spark.hadoop.fs.defaultFS        hdfs://ns-ha
spark.yarn.stagingDir            hdfs://ns-ha/tmp
spark.hadoop.yarn.resourcemanager.address    hadoop-worker1:8032
spark.hadoop.yarn.resourcemanager.scheduler.address    hadoop-worker1:8030

# Hive Metastore
spark.sql.warehouse.dir            hdfs://ns-ha/user/hive/warehouse # HDFS
spark.sql.catalogImplementation     hive
spark.hadoop.hive.metastore.uris    thrift://hive:9083

# dynamic partition
spark.sql.sources.partitionOverwriteMode dynamic

# logs & Checkpoint
spark.eventLog.enabled             true
spark.eventLog.dir                 hdfs://ns-ha/spark-logs
spark.history.fs.logDirectory       hdfs://ns-ha/spark-logs

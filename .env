# <<<<<<<<<<<<<<<<<<<<<<<<<<>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
# make .env public is for helping you deploy the testing hadoop cluster using docker-compose.yml
# <<<<<<<<<<<<<<<<<<<<< Start - Your Config >>>>>>>>>>>>>>>>>>>>>>>>>>>

# Replace ${HADOOP_DATA_LOCAL_MOUNT_PATH} by your local valid path, to mount the hadoop cluster data
HADOOP_DATA_LOCAL_MOUNT_PATH=/Users/smars/bigdata-cluster-volume/hadoop-master/data

# You may replace image name if you changed the pulled image name yourself
HADOOP_MASTER_IMAGE=smarsbhu/proj1-dwh-cluster:hadoop-master-smars-1.1.2
HADOOP_WORKER1_IMAGE=smarsbhu/proj1-dwh-cluster:hadoop-worker1-smars-1.1.2
HADOOP_WORKER2_IMAGE=smarsbhu/proj1-dwh-cluster:hadoop-worker2-smars-1.1.2
MYSQL_HIVE_METASTORE_IMAGE=smarsbhu/proj1-dwh-cluster:mysql-hive-metastore-smars-1.1.2
HIVE_IMAGE=smarsbhu/proj1-dwh-cluster:hive-smars-1.1.2
SPARK_IMAGE=smarsbhu/proj1-dwh-cluster:spark-smars-1.1.1
ORACLE_OLTP_IMAGE=smarsbhu/proj1-dwh-cluster:oracle-oltp-smars-1.1.1
AIRFLOW_IMAGE=smarsbhu/proj1-dwh-cluster:airflow-smars-1.1.1

# Customize your localhost port config if you wish (you may want to change them to avoid port conflicts)
LOCALHOST_SSH_PORT_HADOOP_MASTER=2222
LOCALHOST_SSH_PORT_HADOOP_WORKER1=2223
LOCALHOST_SSH_PORT_HADOOP_WORKER2=2224
LOCALHOST_SSH_PORT_SPARK=2226
LOCALHOST_HDFS_PORT=8020
LOCALHOST_HDFS_NN1_WEB_UI=9870
LOCALHOST_HDFS_NN2_WEB_UI=9871
LOCALHOST_YARN_RM1_WEB_UI=8088
LOCALHOST_YARN_RM2_WEB_UI=8089
LOCALHOST_YARN_NM1_LOG_WEB_UI=8042
LOCALHOST_YARN_NM2_LOG_WEB_UI=8043
LOCALHOST_YARN_NM3_LOG_WEB_UI=8044
LOCALHOST_YARN_JOB_HISTORY_SERVER=19888
LOCALHOST_HIVE_SERVER2_PORT=10000
LOCALHOST_HIVE_SERVER2_2ND_PORT=10002
LOCALHOST_HIVE_METASTORE_PORT=9083
LOCALHOST_MYSQL=3306
LOCALHOST_ORACLE_CONNECT=1521
LOCALHOST_ORACLE_MANAGE_CONSOLE=5500
LOCALHOST_AIRFLOW_WEB_UI=8080
LOCALHOST_SPARK_WEB_UI=4040
LOCALHOST_SPARK_MASTER=7077
LOCALHOST_SPARK_THRIFT_SERVER_PORT=10001
# <<<<<<<<<<<<<<<<<<<<< End - Your Config >>>>>>>>>>>>>>>>>>>>>>>>>>>

# Environment Variables
HADOOP_CLUSTER_HOSTS_FILE=/etc/hosts
HADOOP_CLUSTER_SSH_CONFIG_FILE=/root/.ssh/config
HADOOP_CLUSTER_BIN_PATH=/usr/local/bin
HADOOP_HOME=/usr/local/opt/module/hadoop # HADOOP_MASTER_IP; HADOOP_WORKER1_IP; HADOOP_WORKER2_IP
ZOOKEEPER_HOME=/usr/local/opt/module/zookeeper # HADOOP_MASTER_IP; HADOOP_WORKER1_IP; HADOOP_WORKER2_IP
HIVE_HOME=/opt/hive # HIVE Server
HIVE_HADOOP_HOME=/opt/hadoop  # HIVE Server
HIVE_JDK=/usr/lib/jvm/java-8-openjdk-amd64
SPARK_HADOOP_HOME=/opt/hadoop # SPARK Server
SPARK_HOME=/opt/spark # SPARK Server
AIRFLOW_HOME=/opt/airflow/ # Airflow Server

# Network ipam config
HADOOP_SUBNET=172.18.0.0/16
HADOOP_GATEWAY=172.18.0.1
# Hadoop Master & Worker IP
HADOOP_MASTER_IP=172.18.0.2
HADOOP_WORKER1_IP=172.18.0.3
HADOOP_WORKER2_IP=172.18.0.4
# MYSQL, HIVE, SPARK 
MYSQL_IP=172.18.0.5
HIVE_IP=172.18.0.6
SPARK_IP=172.18.0.7
ORACLE_OLTP_IP=172.18.0.8
AIRFLOW_IP=172.18.0.9

# MySQL Metastore Password
MYSQL_ROOT_PASSWORD=Whos3301919!

# HIVE 
METASTORE_HOST=mysql-hive-metastore
METASTORE_USERNAME=root
METASTORE_PASSWORD=Whos3301919!

# ORACLE-OLTP
ORACLE_SID=ORCLCDB
ORACLE_PDB=ORCLPDB1
ORACLE_PWD=MyStrongPassw0rd
ORACLE_CHARACTERSET=AL32UTF8

# Ports
CONTAINER_INTERNAL_SSH_PORT=22
CONTAINER_INTERNAL_HDFS_PORT=8020
CONTAINER_HDFS_WEB_UI=9870
CONTAINER_YARN_RM1_WEB_UI=8088
CONTAINER_YARN_RM2_WEB_UI=8089
CONTAINER_YARN_LOG_WEB_UI=8042
CONTAINER_YARN_JOB_HISTORY_SERVER=19888
CONTAINER_HIVE_SERVER2_PORT=10000
CONTAINER_HIVE_SERVER2_2ND_PORT=10002
CONTAINER_HIVE_METASTORE_PORT=9083
CONTAINER_MYSQL=3306
CONTAINER_SPARK_WEB_UI=4040
CONTAINER_SPARK_MASTER=7077
CONTAINER_SPARK_THRIFT_SERVER_PORT=10000
CONTAINER_ORACLE_CONNECT=1521  # default port used for database connections
CONTAINER_ORACLE_MANAGE_CONSOLE=5500  #  associated with the Oracle Enterprise Manager Console
CONTAINER_AIRFLOW_WEB_UI=8080

